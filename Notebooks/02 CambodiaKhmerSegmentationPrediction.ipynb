{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksMN1dbJbiTZ"
   },
   "source": [
    "# Image Segmentation Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For several testareas, with georeferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unyF_YP0biTc"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "43-zWMEYbiTc"
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import gc # garbage collector\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for docker compatibility in Ubuntu (pytorch bug)\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5zH5Yelner01"
   },
   "outputs": [],
   "source": [
    "# everything happens in 'path' (except the model file)\n",
    "path = Path(\"../Data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yv9X04iNw0w"
   },
   "source": [
    "#### Choose class and other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERSION = \"C46\" # BASELINE\n",
    "#VERSION = \"C83\" # new BASELINE\n",
    "VERSION = \"C99b\" # new BASELINE\n",
    "\n",
    "VERSION = \"D127b\"\n",
    "VERSION = \"C105c\"\n",
    "VERSION = \"C108\"\n",
    "\n",
    "#MERGE_AREAS = False\n",
    "MERGE_AREAS = True\n",
    "\n",
    "CONVERT_MASK = False\n",
    "#CONVERT_MASK = True # NO LONGER REQUIRED!?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ImyXnyUt47gZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('reservoir', './models/', 'm_*C108_')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should we use Nvidia CUDA?\n",
    "#use_CUDA = False\n",
    "use_CUDA = True\n",
    "\n",
    "# what class(es) are we predicting?\n",
    "myclass = \"reservoir\"\n",
    "\n",
    "# use TTA (test time augmentation)? Does not work with my Deeplab implementation though.\n",
    "use_TTA = False\n",
    "#use_TTA = True\n",
    "\n",
    "############## TODO ### \n",
    "# where is my pre-trained model?\n",
    "learner_path = \"./models/\"\n",
    "\n",
    "# nnet model file name\n",
    "nnet = \"m_*\" + VERSION + \"_\"\n",
    "#nnet = \"m_d*\" + VERSION + \"_\"\n",
    "#nnet = \"m_h*\" + VERSION + \"_\"\n",
    "#nnet = 'stage-1_*'+ VERSION + \"_\"\n",
    "\n",
    "myclass, learner_path, nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to images, i.e. which ones should be predicted?\n",
    "image_path_list = [  \n",
    "    #[path/'Deeplearningtrialarea2/BingImages_zoom_19',      path/'Deeplearningtrialarea2/PredictedMasks'],\n",
    "    ####[path/'Deeplearningtrialarea2_overlap/BingImages',      path/'Deeplearningtrialarea2_overlap/PredictedMasks'],\n",
    "    [path/'TinyTestareaGAR/BingImages_zoom_19',   path/'TinyTestareaGAR/PredictedMasks_zoom_19'], \n",
    "    # EITHER!!\n",
    "    #[path/'TinyTestareaGAR/BingImagesOffset_zoom_19',   path/'TinyTestareaGAR/PredictedMasksOffset_zoom_19'],\n",
    "    [path/'SrokTest/BingImages_zoom_19',   path/'SrokTest/PredictedMasks_zoom_19'],\n",
    "    [path/'Srok2Test/BingImages_zoom_19',   path/'Srok2Test/PredictedMasks_zoom_19'],\n",
    "    #[path/'Feb10Test/BingImages_zoom_19',   path/'Feb10tTest/PredictedMasks_zoom_19'],\n",
    "\n",
    "    # same for training data:\n",
    "    [path/'TrainingData/Reservoirs_Sep10_zoom_19', path/'TrainingData/PredictedMasks_Sep10_zoom_19'],\n",
    "    [path/'TrainingData/Reservoirs_Sep26_zoom_19', path/'TrainingData/PredictedMasks_Sep26_zoom_19'],\n",
    "    [path/'TrainingData/Reservoirs_Dec05_zoom_19', path/'TrainingData/PredictedMasks_Dec05_zoom_19'],\n",
    "    [path/'TrainingData/Reservoirs_Feb02_zoom_19', path/'TrainingData/PredictedMasks_Feb02_zoom_19'],\n",
    "    [path/'TrainingData/Reservoirs_Feb10_zoom_19', path/'TrainingData/PredictedMasks_Feb10_zoom_19'],\n",
    "    ### pseudo-labelled training data:\n",
    "    #[path/'TrainingData/Reservoirs_TestArea3-edited_zoom_19', path/'TrainingData/PredictedMasks_TestArea3-edited_zoom_19'],\n",
    "    #[path/'TrainingData/Reservoirs_4000_zoom_19', path/'TrainingData/PredictedMasks_4000_zoom_19'],\n",
    "    #[path/'TrainingData/Reservoirs_Klassen_ML_April20_zoom_19', path/'TrainingData/PredictedMasks_Klassen_ML_April20_zoom_19'],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to images, i.e. which ones should be predicted?\n",
    "image_path_list = [  \n",
    "    ##[path/'TinyTestareaGAR/BingImagesOffset_zoom_19',   path/'TinyTestareaGAR/PredictedMasksOffset_zoom_19'],\n",
    "    #[path/'SrokTest/BingImages_zoom_19',   path/'SrokTest/PredictedMasks_zoom_19'],\n",
    "    [path/'GAR_large/BingImages_zoom_19',   path/'GAR_large/PredictedMasks_zoom_19'],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom level\n",
    "zoom = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy functions, just needs to exist, never invoked.\n",
    "def segmentron_splitter(model): return False\n",
    "### mask function dummy, just needs to exist, never invoked\n",
    "def get_msk(fn):  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/m_deeplabv3+_C108_reservoir0.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we collect all model *.pkl files of our class for ensembling their predictions\n",
    "import glob\n",
    "ensemble_list = sorted(glob.glob(learner_path+nnet+myclass+\"*\"))\n",
    "\n",
    "# intermediate models are labelled \"stage\" and must be excluded:\n",
    "#ensemble_list = [m for m in ensemble_list if \"stage\" not in m ]\n",
    "\n",
    "ensemble_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/m_deeplabv3+_C108_reservoir0.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "#ensemble_list = [ensemble_list[0]]\n",
    "ensemble_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# create a testset and predict \n",
    "def predict(imagelist, myclass, ensemble_list, use_TTA=False):\n",
    "    no_fold = len(ensemble_list) # number of available models to iterate over\n",
    "    \n",
    "    firstTime = True\n",
    "    # we iterate over the ensembled models:\n",
    "    for fold in ensemble_list:\n",
    "        #fold =\"m_deeplabv3+_D02_reservoir_9\"\n",
    "        print (\"---\", fold)\n",
    "        learn=load_learner(fold)\n",
    "        learn.loss_func=FocalLossFlat(axis=1) ### ? ?? Needed\n",
    "    \n",
    "        if use_CUDA:# put it all to GPU\n",
    "            dl_test = learn.dls.test_dl(imagelist).to('cuda')\n",
    "            learn.model = learn.model.cuda()\n",
    "            learn.dls.to('cuda')\n",
    "        else:\n",
    "            dl_test = learn.dls.test_dl(imagelist)\n",
    "\n",
    "        #assert(0==1)\n",
    "\n",
    "        if not use_TTA:\n",
    "            predictions = learn.get_preds(dl=dl_test)  \n",
    "        else: # with test time augmentation TTA. Better results but takes much longer\n",
    "            predictions = learn.tta(dl=dl_test)\n",
    "        \n",
    "        # free some memory.\n",
    "        del learn; gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "        # this is the ensembling, we compute the mean iteratively\n",
    "        if firstTime:\n",
    "            firstTime=False\n",
    "            # initialization:\n",
    "            preds = predictions[0]/no_fold\n",
    "        else:\n",
    "            # subsequently we add the other predictions and divide by the number of models\n",
    "            # this results in computing the mean\n",
    "            preds += predictions[0]/no_fold\n",
    "       \n",
    "        del predictions # free some memory.\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from numpy import savetxt\n",
    "\n",
    "# this stores the prediction as greyscale images. Predicted masks are scaled to [0..255] ubyte greyscale.\n",
    "def save_predicted_masks_FULL(imagelist, metalist, preds, myclass, mask_path):\n",
    "    for i, pred in enumerate(preds):\n",
    "        filename = imagelist[i].stem.replace('lidar', 'mask_') + myclass + '.tif'\n",
    "        pred_scale = np.uint8((pred[1]*255).numpy())\n",
    "        \n",
    "        with rio.open(mask_path/filename, \"w\", **metalist[i]) as dest:\n",
    "            dest.write(pred_scale, indexes=1)\n",
    "        \n",
    "        #savetxt(mask_path/(filename+\".csv\"), pred_scale, fmt=\"%d\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "class SegmentationAlbumentationsTransform(ItemTransform):\n",
    "    split_idx = 0\n",
    "    def __init__(self, aug): self.aug = aug\n",
    "    def encodes(self, x):\n",
    "        img,mask = x\n",
    "        aug = self.aug(image=np.array(img), mask=np.array(mask))\n",
    "        return PILImage.create(aug[\"image\"]), PILMask.create(aug[\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss:\n",
    "    \"Dice and Focal combined\"\n",
    "    def __init__(self, axis=1, smooth=1., alpha=1.):\n",
    "        store_attr()\n",
    "        self.focal_loss = FocalLossFlat(axis=axis)\n",
    "        self.dice_loss =  DiceLoss(axis, smooth)\n",
    "        \n",
    "    def __call__(self, pred, targ):\n",
    "        return self.focal_loss(pred, targ) + self.alpha * self.dice_loss(pred, targ)\n",
    "    \n",
    "    def decodes(self, x):    return x.argmax(dim=self.axis)\n",
    "    def activation(self, x): return F.softmax(x, dim=self.axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['background', 'reservoir'], dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = np.array(['background', myclass])\n",
    "codes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def my_transforms(imgsize):\n",
    "    item_tfms = [Resize(imgsize[0]), #SegmentationAlbumentationsTransform(A.CLAHE())\n",
    "                ]\n",
    "    batch_tfms=[*aug_transforms(size=imgsize[0], min_scale=.6,\n",
    "                    #ratio=(1.,1.),\n",
    "                    xtra_tfms=[RandomErasing(p=0.5, sl=0.0, sh=0.2, min_aspect=0.3, max_count=6)],\n",
    "                    max_rotate=0, max_warp=0), Normalize.from_stats(*imagenet_stats)]\n",
    "    return item_tfms, batch_tfms\n",
    "\n",
    "item_tfms, batch_tfms = my_transforms((512,512))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mydf = pd.DataFrame([], columns=['fpath', \"is_valid\"])\n",
    "bs=40"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dblock = DataBlock(blocks=(ImageBlock, MaskBlock(codes=codes)),\n",
    "               #splitter=RandomSplitter(valid_pct=0.2),\n",
    "               splitter=ColSplitter(), #!!! is_valid is in valid_ds\n",
    "               get_x=ColReader('fpath'),\n",
    "               get_y=get_msk, item_tfms=item_tfms, batch_tfms=batch_tfms)\n",
    "# the dataloaders\n",
    "dls = dblock.dataloaders(mydf, path='', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  ../Data/GAR_large/BingImages_zoom_19 2107 ../Data/GAR_large/PredictedMasks_zoom_19\n",
      "--- ./models/m_deeplabv3+_C108_reservoir0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.9 s, sys: 9.97 s, total: 1min 6s\n",
      "Wall time: 57.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not ensemble_list:\n",
    "    print(\"!!! NO AI MODELS !!! STOPPING\")\n",
    "else:\n",
    "    # here comes the prediction loop:\n",
    "    for image_path, mask_path in image_path_list:\n",
    "        imagelist = get_image_files(image_path, recurse=False)\n",
    "        #imagelist = imagelist[1499:]\n",
    "        print (\">> \", image_path, len(imagelist), mask_path)\n",
    "        if not os.path.exists(mask_path): os.makedirs(mask_path)\n",
    "            \n",
    "        # here we collect the predictions from the ensemble\n",
    "        preds = predict(imagelist, myclass, ensemble_list, use_TTA)\n",
    "    \n",
    "        # save predictions as GeoTiff images\n",
    "        for i, pred in enumerate(preds):\n",
    "            filename = imagelist[i].stem.replace('lidar', 'mask_') + '.tif'\n",
    "            pred_scale = np.uint8((pred[1]*255).numpy())\n",
    "            if CONVERT_MASK: pred_scale[pred_scale<128] = 0\n",
    "\n",
    "            out_meta = rio.open(imagelist[i]).meta.copy()\n",
    "            out_meta.update({\"count\": 1, # singleband greyscale\n",
    "                             \"compress\": \"LZW\"}) \n",
    "\n",
    "            with rio.open(mask_path/filename, \"w\", **out_meta) as dest:\n",
    "                dest.write(pred_scale, indexes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MERGE_AREAS: assert(0==1) # brute force halt:-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge reservoirs in training areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.merge import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_merge(old_data, new_data, old_nodata, new_nodata, index=None, roff=None, coff=None):\n",
    "    old_data[:] = np.mean([old_data, new_data], axis=0)  # <== NOTE old_data[:] updates the old data array *in place*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeDir2mosaic(downloadDir, mergeDir):\n",
    "    file_pattern =  \"/r_*_*_*_\" + str(zoom)+\".tif\"\n",
    "    file_list = glob.glob(downloadDir+file_pattern)\n",
    "\n",
    "    df = pd.DataFrame(file_list, columns=[\"fpath\"])\n",
    "    df['ID']= df['fpath'].str.split(\"_\").str[-5]\n",
    "\n",
    "    #print (df.head(10))\n",
    "    print ('reservoirs:', df['ID'].nunique(), \"snippets:\", len(df))\n",
    "    \n",
    "    # now merge\n",
    "    for i in df['ID'].unique(): \n",
    "        file_list = df[df['ID'] == i]['fpath']\n",
    "        print (i, len(file_list))\n",
    "        \n",
    "        src_files_to_mosaic = []\n",
    "        for fp in file_list:\n",
    "            src = rio.open(fp)\n",
    "            src_files_to_mosaic.append(src) \n",
    "\n",
    "        mosaic, out_trans = merge(src_files_to_mosaic,method='max')\n",
    "        #mosaic, out_trans = merge(src_files_to_mosaic,method=custom_merge)\n",
    "    \n",
    "        out_meta = src.meta.copy() # get meta from any src\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "            \"height\": mosaic.shape[1],\n",
    "            \"width\": mosaic.shape[2],\n",
    "            \"transform\": out_trans })\n",
    "        with rio.open(mergeDir+\"/\"+str(i)+\".tif\", \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1e+03 ns, total: 8 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for _, m in image_path_list:\n",
    "    maskDir = str(m) # remove Path\n",
    "    if \"TrainingData\" in maskDir: # this is training\n",
    "        mergeDir = maskDir.replace(\"PredictedMasks\", \"PredictedReservoirs\")\n",
    "        if not os.path.exists(mergeDir): os.makedirs(mergeDir)\n",
    "        for f in glob.glob(mergeDir+\"/*\"): os.remove(f)\n",
    "        print (mergeDir)\n",
    "        mergeDir2mosaic(maskDir, mergeDir)\n",
    "        print (\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge testareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/GAR_large/PredictedMasks_zoom_19 2107\n",
      "../Data/GAR_large/allofit_predicted_C108.tif\n"
     ]
    }
   ],
   "source": [
    "#%%time \n",
    "from shutil import copyfile\n",
    "\n",
    "for _, m in image_path_list:\n",
    "    #maskDir = str(m) # remove Path\n",
    "    if \"Test\" in str(m) or True: # this is a Testarea\n",
    "        mergeFile = m.parent/'allofit_predicted.tif'\n",
    "        mergeFile2 = m.parent/('allofit_predicted_'+VERSION+'.tif')\n",
    "\n",
    "        file_list = glob.glob(str(m)+'/*.tif')\n",
    "        print (m, len(file_list))\n",
    "    \n",
    "        # now merge\n",
    "        src_files_to_mosaic = []\n",
    "        for fp in file_list:\n",
    "            src = rio.open(fp)\n",
    "            src_files_to_mosaic.append(src) \n",
    "       \n",
    "        mosaic, out_trans = merge(src_files_to_mosaic, method='max') #super easy!!!\n",
    "        #mosaic, out_trans = merge(src_files_to_mosaic, method='first') #super easy!!!\n",
    "        #mosaic, out_trans = merge(src_files_to_mosaic,method=custom_merge)\n",
    "\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "            \"height\": mosaic.shape[1],\n",
    "            \"width\": mosaic.shape[2],\n",
    "            \"transform\": out_trans,\n",
    "            \"compress\": \"lzw\",})\n",
    "        with rio.open(mergeFile, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)\n",
    "        \n",
    "        copyfile(mergeFile, mergeFile2)\n",
    "        print (mergeFile2)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "IgfhU0zObiTq",
    "6z8pe1eqbiTv",
    "QeePnewEbiTy"
   ],
   "name": "Segmentation_010.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
